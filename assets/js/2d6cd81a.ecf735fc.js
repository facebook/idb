"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[986],{7461:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"video","title":"Video","description":"idb provides recordings and streams of an attached iOS Simulator or Device. This can be very useful for exposing an iOS Target\'s screen, or recording an automation for later review.","source":"@site/docs/video.mdx","sourceDirName":".","slug":"/video","permalink":"/docs/video","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"video","title":"Video"},"sidebar":"docs","previous":{"title":"FBDeviceControl","permalink":"/docs/fbdevicecontrol"},"next":{"title":"Test Execution","permalink":"/docs/test-execution"}}');var t=n(4848),s=n(8453);const o={id:"video",title:"Video"},a=void 0,d={},c=[{value:"Recording",id:"recording",level:2},{value:"Streaming",id:"streaming",level:2}];function l(e){const i={a:"a",code:"code",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.code,{children:"idb"})," provides recordings and streams of an attached iOS Simulator or Device. This can be very useful for exposing an iOS Target's screen, or recording an automation for later review."]}),"\n",(0,t.jsx)(i.h2,{id:"recording",children:"Recording"}),"\n",(0,t.jsxs)(i.p,{children:["If you wish to make a recording for a target you can use ",(0,t.jsx)(i.code,{children:"idb record-video FILE_PATH"}),"."]}),"\n",(0,t.jsxs)(i.p,{children:["This can be used to record an mp4 file to disk. The specified ",(0,t.jsx)(i.code,{children:"FILE_PATH"})," can be any location on disk, regardless of the extension it will be an ",(0,t.jsx)(i.code,{children:"mp4"})," video. The video recording will start upon invoking the command, the recording can be stopped by sending a ",(0,t.jsx)(i.code,{children:"SIGTERM"})," to the process (i.e. Ctrl-C in a terminal). The video file will only be written to disk upon exit of the ",(0,t.jsx)(i.code,{children:"idb"})," process."]}),"\n",(0,t.jsx)(i.h2,{id:"streaming",children:"Streaming"}),"\n",(0,t.jsxs)(i.p,{children:["Video streaming allows for live frames to be captured from the iOS Target. Typically, this stream should be piped through another application for consumption, depending on the use-case. ",(0,t.jsx)(i.code,{children:"idb"})," provides raw access to the video, in a variety of encodings, it's left to the user to decide how to combine this with a downstream video streaming pipeline. Streaming video pairs well with ",(0,t.jsx)(i.a,{href:"accessibility",children:"Accessibility commands."})]}),"\n",(0,t.jsxs)(i.p,{children:["Projects such as ",(0,t.jsx)(i.a,{href:"https://www.ffmpeg.org",children:(0,t.jsx)(i.code,{children:"ffmpeg"})})," or ",(0,t.jsx)(i.a,{href:"https://gstreamer.freedesktop.org",children:(0,t.jsx)(i.code,{children:"gstreamer"})})," are examples of these applications. For example, ",(0,t.jsx)(i.code,{children:"ffmpeg"})," can accept streamed ",(0,t.jsx)(i.code,{children:"h264"})," video and expose this over a UDP socket with intermediate transcoding of data."]}),"\n",(0,t.jsx)(i.p,{children:"For example, the following invocation can be used to start a video stream and expose it on UDP port."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{children:"$ idb video-stream --fps 30 --format h264 --compression-quality 1.0 --udid EE074DCE-7D75-4F96-A949-82252F5FEC30 | ffmpeg -f h264 -i pipe:0 -vcodec copy -tune zerolatency -b 900k -framerate 30 -f mpegts udp://0.0.0.0:12345\n"})}),"\n",(0,t.jsx)(i.p,{children:"Breaking this command down:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"idb video-stream"})," is the command used in idb to stream video out."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"--fps 30"})," is the number of frames that are produced by ",(0,t.jsx)(i.code,{children:"idb"})," per second. This can be arbitrarily large or small. A higher frame rate will increase system utilization. Increasing the fps may not result in smoother presentation, as an iOS Simulator may be refreshing it's screen less frequently than the target frame rate. Typically an iOS Simulator may not render transparencies at 60fps."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"--format h264"})," represents the format of the video stream itself. A variety of outputs are available:","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"h264"})," This is an ",(0,t.jsx)(i.a,{href:"https://en.wikipedia.org/wiki/Network_Abstraction_Layer#NAL_Units_in_Byte-Stream_Format_Use",children:"Annexe-B H.264 Stream"})]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"rbga"})," is a stream of raw RBGA bytes."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"mjpeg"})," is an stream of encoed JPEG images, ",(0,t.jsx)(i.a,{href:"https://en.wikipedia.org/wiki/Motion_JPEG",children:"typically called MJPEG"}),"."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"minicap"})," is ",(0,t.jsx)(i.a,{href:"https://github.com/openstf/minicap",children:"format used by the minicap project"}),". It's fundementally a MJPEG stream with a header at the start of the stream and length ",(0,t.jsx)(i.a,{href:"https://github.com/openstf/minicap#global-header-binary-format",children:"headers per frame"}),"."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"--compression-quality 1.0"})," represents the quality level used for encoded frames, this is a value between 0.0 and 1.0. It applies to all formats except for the raw ",(0,t.jsx)(i.code,{children:"rbga"})," format."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"idb video-stream"})," takes a positional argument for a file path to stream to. When this is not provided, video will be streamed to ",(0,t.jsx)(i.code,{children:"stdout"}),", this can also be achieved by passing ",(0,t.jsx)(i.code,{children:"-"})," as the file path argument.","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["The output of the idb command is piped to ",(0,t.jsx)(i.code,{children:"ffmpeg"})," in the shell. Pipelining via ",(0,t.jsx)(i.code,{children:"stdout"})," is the easiest way of sending video data from ",(0,t.jsx)(i.code,{children:"idb"})," to an external program (as opposed to using a file)."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(i.li,{children:["The arguments for ",(0,t.jsx)(i.code,{children:"ffmpeg"})," relate to:","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["The parsing of input video from ",(0,t.jsx)(i.code,{children:"stdin"}),": ",(0,t.jsx)(i.code,{children:"-f h264 -i pipe:0"}),"."]}),"\n",(0,t.jsxs)(i.li,{children:["Transcoding it to a lower bitrate and for real-time delivery ",(0,t.jsx)(i.code,{children:"-tune zerolatency -b 900k"}),"."]}),"\n",(0,t.jsxs)(i.li,{children:["Exposing the transcoded video over UDP so that it can be consumed by another application over the network ",(0,t.jsx)(i.code,{children:"udp://0.0.0.0:12345"}),"."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>o,x:()=>a});var r=n(6540);const t={},s=r.createContext(t);function o(e){const i=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),r.createElement(s.Provider,{value:i},e.children)}}}]);